{
    "Slug": "accelerate-data-analytics-with-spark-connector-for-azure-sql-database-sql-server",
    "Title": "Accelerate real-time big data analytics with Spark connector for Microsoft SQL Databases",
    "Summary": "Apache Spark is a unified analytics engine for large-scale data processing. Today you can use the built-in JDBC connector to connect to Azure SQL Database or SQL Server to read or write data from Spark jobs.",
    "Content": "<p>Apache Spark is a unified analytics engine for large-scale data processing. Today, you can use the built-in JDBC connector to connect to Azure SQL Database or SQL Server to read or write data from Spark jobs.</p>\n\n<p>The Spark connector for Azure SQL Database and SQL Server enables SQL databases, including Azure SQL Database and SQL Server, to act as input data source or output data sink for Spark jobs. It allows you to utilize real-time transactional data in big data analytics and persist results for adhoc queries or reporting.</p>\n\n<p>Compared to the built-in Spark connector, this connector provides the ability to bulk insert data into SQL databases. It can outperform row-by-row insertion with 10x to 20x faster performance. The Spark connector for Azure SQL Databases and SQL Server also supports Azure Active Directory authentication. It allows you to securely connect to your Azure SQL database from Azure Databricks using your AAD account. The Spark connector also provides similar interfaces with the built-in JDBC connector and is easy to migrate your existing Spark jobs to use this new connector.</p>\n\n<p>The Spark connector for Azure SQL Database and SQL Server utilizes the Microsoft JDBC Driver for SQL Server to move data between Spark worker nodes and SQL databases:</p>\n\n<ol>\n <li>The Spark master node connects to SQL Server or Azure SQL Database and loads data from a specific table or using a specific SQL query.</li>\n <li>The Spark master node distributes data to worker nodes for transformation.</li>\n <li>The Worker node connects to SQL Server or Azure SQL Database and writes data to the database. The user can choose to use row-by-row insertion or bulk insert.</li>\n</ol>\n\n<p><a href=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/eb01605f-8999-4c13-be13-3c64d76084a8.png\"><img width=\"755\" height=\"418\" title=\"clip_image002[5]\" style=\"border: 0px currentcolor; border-image: none; padding-top: 0px; padding-right: 0px; padding-left: 0px; margin-right: auto; margin-left: auto; float: none; display: block; background-image: none;\" alt=\"clip_image002[5]\" src=\"https://azurecomcdn.azureedge.net/mediahandler/acomblog/media/Default/blog/f66338dc-6d72-449d-be9f-a868429279b6.png\" border=\"0\"></a></p>\n\n<p><br>\nTo get started, visit the <a href=\"https://github.com/Azure/azure-sqldb-spark\">azure-sqldb-spark repository</a> on GitHub. You can also find the <a href=\"https://github.com/Azure/azure-sqldb-spark/tree/master/samples/notebooks\">Sample Azure Databricks notebooks</a> and <a href=\"https://github.com/Azure/azure-sqldb-spark/tree/master/samples/scripts\">Sample scripts in Scala</a> in the same repository. You can also find more details from <a href=\"https://docs.microsoft.com/en-us/azure/sql-database/sql-database-spark-connector\" target=\"_blank\">online documentation</a>.</p>\n\n<p>You might also want to review the <a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html\">Apache Spark SQL</a>, <a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html\">DataFrames</a>, and <a href=\"https://spark.apache.org/docs/latest/sql-programming-guide.html\">Datasets Guide</a> and the <a href=\"https://github.com/Azure/azure-sqldb-spark\">Azure Databricks documentation</a> to learn more details about Spark and Azure Databricks.</p>"
}