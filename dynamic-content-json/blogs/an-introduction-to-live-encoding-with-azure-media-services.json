{
    "Slug": "an-introduction-to-live-encoding-with-azure-media-services",
    "Title": "An introduction to Live Encoding with Azure Media Services",
    "Summary": "In this blog, I will provide an overview of this Live Encoding feature, which adds the following capabilities to Azure Media Services.",
    "Content": "<div style=\"background:#eee;border:1px solid #ccc;padding:5px 10px;\"><strong>Updated on April 19, 2019: </strong>Azure Media Services has evolved since this 2015 blog post. For the current capabilities of the service, please refer to our documentation, &ldquo;<a href=\"https://docs.microsoft.com/en-us/azure/media-services/latest/live-streaming-overview\">Live streaming with Azure Media Services v3</a>&rdquo; and &ldquo;<a href=\"https://docs.microsoft.com/en-us/azure/media-services/latest/live-events-outputs-concept\">Live Events and Live Outputs</a>.&rdquo; In particular, the sections below on supported formats, codecs, and input protocol have since been updated.</div>\n\n<p>Since our release of Live Streaming in Azure Media Services last year, you have had access to the same instantly scalable, always available streaming solution that broadcasters have used time and again to deliver live events to millions of customers. You may have read through my colleagues&rsquo; blogs on <a href=\"https://azure.microsoft.com/blog/2014/09/10/getting-started-with-live-streaming-using-the-azure-management-portal/\" target=\"_blank\">using the Azure Management Portal</a> or <a href=\"https://azure.microsoft.com/blog/2014/11/04/getting-started-with-live-streaming-using-the-media-services-sdk-2/\" target=\"_blank\">our .NET SDK</a> to manage live events, and on how to <a href=\"https://azure.microsoft.com/blog/2014/09/18/azure-media-services-rtmp-support-and-live-encoders/\" target=\"_blank\">produce a live feed</a>.&nbsp;However, previously, in order to use Live Streaming, you were required to use an on-premises encoder to produce an adaptive bitrate video stream and push that to the cloud. With the preview release of Live Encoding, you can instead send a single bitrate live feed to Azure Media Services, have it encoded into an adaptive bitrate stream and deliver it to a wide variety of clients in delivery in MPEG-DASH, Microsoft Smooth Streaming, Apple HLS, or Adobe HDS formats. In this blog, I will provide an overview of this Live Encoding feature, which adds the following capabilities to Azure Media Services:</p>\n\n<ul>\n <li>Live encoding of a single bitrate live feed into an adaptive bitrate stream</li>\n <li>Ability to ingest a live feed over RTP protocol (MPEG Transport Streams), RTMP and Smooth Streaming</li>\n <li>Ability to control insertion of slates, as well as to signal insertion of advertisements to the client</li>\n <li>Ability to get a thumbnail preview of the live feed</li>\n</ul>\n\n<h2>What is Live Encoding?</h2>\n\n<p>When you are streaming a live event, your goal is&nbsp; to deliver high quality video, under a variety of network conditions, to every device that your customers could possibly have. The problems of quality and network conditions have a solution: <a href=\"https://en.wikipedia.org/wiki/Adaptive_bitrate_streaming\" target=\"_blank\">adaptive bitrate streaming</a>. And the solution to the problem of multiple devices (and their capabilities) is a re-packaging system such as <a href=\"https://go.microsoft.com/fwlink/?linkid=276874\" target=\"_blank\">dynamic packaging</a>. Adaptive bitrate streaming works by encoding the video into multiple video streams at different resolutions and bitrates, while keeping them synchronized. In addition, for a live event, you need to keep latency to a manageable number by processing the incoming video in real-time. This real-time video compression is Live Encoding, and it requires a lot of compute cycles. To stream live events, you are now looking at hardware boxes with fast CPUs, perhaps GPU acceleration. In addition, you are producing several (6 to 10) video streams, which means you also&nbsp;need a lot of bandwidth to get those streams to a CDN, which can then deliver the event to your customers. Your infrastructure costs start to add up&hellip; Live Encoding in Azure Media Services is a cloud based workflow that addresses such infrastructure concerns. With this feature, you only need to send in a single (high quality) video feed into an Azure data center , and the service handles the compute-intensive work of encoding it into an adaptive bitrate stream. This means you can run live events from remote locations (paying only for a good, fast WiFi or mobile network), and encoders built into cameras, or less expensive (even free) encoders that require less power. Our services are instantly scalable, which means you can handle spikes in your event schedules paying only for what you use.</p>\n\n<h2>How do I use Live Encoding?</h2>\n\n<p>You can set up Live Encoding to deliver live events via the following steps:</p>\n\n<ol>\n <li>Decide on which protocol you will use for the input live feed (see section below)</li>\n <li>Create a live Channel using our APIs or the Azure Management Portal, and choose the settings that meet your live encoding needs</li>\n <li>Set up an on-premises encoder to send in the single (high quality) video feed</li>\n <li>Preview the output stream, via the Azure Management Portal, for example</li>\n <li>Create Programs to <a href=\"https://azure.microsoft.com/en-us/documentation/articles/media-services-manage-channels-overview/\" target=\"_blank\">manage your events</a></li>\n</ol>\n\n<p>Note: you can get the details about the APIs, and configuration steps through upcoming blog posts.</p>\n\n<h2>Supported formats and codecs</h2>\n\n<p>The input protocols supported by Live Encoding are: RTMP, RTP (MPEG TS) and Smooth Streaming. You can send in a live feed where the video is encoded with MPEG-2 (up to 422 Profile), or H.264 (up to High 422 Profile), and the audio is encoded with AAC-LC (up to 7.1 channels), or Dolby&reg; Digital/AC-3 (up to 7.1 channels), or with MPEG Audio (Layer II and III, up to stereo). The Live Encoder supports chroma subsampling from 4:2:2 to 4:2:0, and de-interlacing, as well as audio channel downmixing, audio resampling and audio dynamic range compression. On the output, the Live Encoder can encode video to H.264 (up to High 4:2:0 Progressive), and audio to stereo or mono-channel AAC (LC, HE v1, HE v2 Profile). The Live Encoder also supports pass through of EIA/CEA-708 closed captions, if present in the input video feed. For signaling advertisements, the Live Encoder supports input via API calls, or, if the&nbsp;input protocol is RTP, in-band&nbsp;SCTE-35 SpliceInsert and TimeSignal commands. On the output, our service can emit HLS Playlist Tags (SCTE-67), Smooth Streaming Sparse Tracks (SCTE-35) and HDS CueInfo Elements.</p>\n\n<h2>Choosing an ingest protocol</h2>\n\n<p>You can send the input live feed to a Channel via one of the following:</p>\n\n<ol>\n <li>RTMP: Most common in prosumer scenarios, where the input feed can be sent over the open internet to a nearby Azure data center, using encoders built into the camera, or using tools&nbsp; like Telestream Wirecast, Flash Media Live Encoder, Tricaster, etc.</li>\n <li>RTP: Catered towards professional broadcasters, with on-premises live encoders from vendors like Elemental Technologies, Ericsson, Ateme,&nbsp; Envivio, etc.&nbsp; The input stream is typically set up in conjunction with&nbsp; an IT department, and using private/dedicated networks such as Microsoft <a href=\"https://azure.microsoft.com/en-us/services/expressroute/\">Azure ExpressRoute</a></li>\n <li>Smooth Streaming over HTTP: Typically&nbsp;used&nbsp;with on-premises live encoders from vendors like Elemental Technologies, Ericsson, Ateme,&nbsp;Envivio, etc. It is usually possible to send the input stream over the open internet to a nearby Azure data center.</li>\n</ol>\n\n<h2>Notes on using RTMP</h2>\n\n<p>When sending a live feed into a Channel over RTMP, the following constraints apply:</p>\n\n<ol>\n <li>Video encoded with H.264 at resolutions up to 1080p30 and stereo audio encoded with AAC-LC</li>\n <li>Audio sampling rate should be 44.1 kHz</li>\n <li>Closed GOP and CBR mode encoding recommended</li>\n <li>Available bandwidth should exceed the aggregate bitrate for video and audio</li>\n</ol>\n\n<h2>Notes on using RTP</h2>\n\n<p>If you are planning to use RTP to send in a live stream, you should expect the following from your network connection:</p>\n\n<ol>\n <li>High throughput (up to 1.5 times the bitrate of the input stream). Since higher bandwidth may only be required during high profile events, but not year round, your choice for the network should allow easy change of bandwidth commitment for reduced cost</li>\n <li>Low latency (under 150ms), with about 10-15 hops as reported by traceroute</li>\n <li>An SLA on QoS and&nbsp;availability</li>\n</ol>\n\n<p>The two recommended approaches are described below. Regardless of the option chosen, a Tier 1 network provider should be used. The list of Tier 1 network providers can be found <a href=\"https://en.wikipedia.org/wiki/Tier_1_network\">here</a>.</p>\n\n<h2>RTP over public internet and Border Gateway&nbsp;Protocol (BGP)&nbsp;peering</h2>\n\n<p>You can use RTP over the public internet and BGP peering with Microsoft Azure network. In this case, Internet capacity, sometimes called High Speed IP (HSIP), is provided by one or more network providers. Video data goes through public Internet and it requires a cross-connect between a network provider&rsquo;s Internet IP edge and Microsoft Azure network at a co-location. This co-location depends on network providers and Microsoft and can be found from <a href=\"https://www.peeringdb.com/\" target=\"_blank\">PeeringDB</a>. The network providers are responsible for Internet delivery services to Azure with industry standard SLAs. This is the approach we used in the current <a href=\"https://news.microsoft.com/2014/02/06/nbc-olympics-production-of-the-2014-olympic-winter-games-to-utilize-microsoft-for-live-and-on-demand-streaming/\">NBC Sports/Sochi Olympics solution</a>, and it often results in lower networking cost.</p>\n\n<h2>RTP over a private/dedicated network</h2>\n\n<p>You can use a network solution which is designed for general data transfer (instead of video specific data) over a dedicated private network. More often, this option is provided through a managed service package from a network provider. What you need may be only a subset of the services offered in the package. The advantage of such managed services is that end-to-end delivery is provided and managed with enhanced SLA. There are two types of services under this category:</p>\n\n<ol>\n <li>Microsoft <a href=\"https://azure.microsoft.com/en-us/services/expressroute/\">Azure ExpressRoute</a> over either a Network Service Provider (NSP) or Exchange Provider, such as Azure ExpressRoute + Level 3 Cloud Connect Solutions or&nbsp; <a href=\"https://www.equinix.com/services/interconnection-connectivity/cloud-exchange/\">Azure ExpressRoute + Equinix Cloud Exchange</a></li>\n <li>Managed video services provided by network provider, such as <a href=\"https://www.level3.com/en/products/vyvx-solutions/\">Level 3 VYVX Solution</a></li>\n</ol>\n\n<p>&nbsp; If you are sending a live feed over RTP, then the common in-transit encoding/container and protocol used are as below:</p>\n\n<ul>\n <li>Encoding: H264/AAC</li>\n <li>Container Format: MPEG-2 TS</li>\n <li>Network Protocol &ndash; Application Layer: RTP Unicast</li>\n <li>Network Protocol &ndash; Transport Layer: UDP</li>\n</ul>\n\n<h2>Using slates and signaling advertisements</h2>\n\n<p>When your Channel has Live Encoding enabled, you have a component in your pipeline that is processing video, and can manipulate it. In our service, you can have the Channel insert slates and/or advertising signals into the outgoing adaptive bitrate stream. Slates are still images that you can use to cover up the input live feed in certain cases (for example during a commercial break). Advertising signals, as the name suggests, are time-synchronized signals you embed into the outgoing stream to tell the video player to take special action &ndash; such as to switch to an advertisement at the appropriate time. See this <a href=\"https://codesequoia.wordpress.com/2014/02/24/understanding-scte-35/\" target=\"_blank\">blog</a> for an overview of the SCTE-35 signaling mechanism used for this purpose. Below is a typical scenario you could implement in your live event (sample code and API details will be available in upcoming blog posts).</p>\n\n<ol>\n <li>Have your viewers get a PRE-EVENT image before the event starts</li>\n <li>Have your viewers get a POST-EVENT image after the event ends</li>\n <li>Have your viewers get an ERROR-EVENT image if there is a problem during the event (eg. power failure in the stadium)</li>\n <li>Send an AD-BREAK image to hide the live event feed during a commercial break</li>\n</ol>\n\n<h2>Getting a thumbnail preview of a live feed</h2>\n\n<p>When Live Encoding is enabled, you can now get a preview of the live feed as it reaches the Channel. This can be a valuable tool to check whether your live feed is actually reaching the Channel. You can access the thumbnail via an API.</p>\n\n<h2>Summary</h2>\n\n<p>In this blog, I have introduced you to the Live Encoding feature in Azure Media Services. In the coming days, there will be many more posts on topics such as using&nbsp;the Azure Management Portal to&nbsp;use Live Encoding, about configuring&nbsp;on-premises encoders to generate the input live feed, how to control slates and ads. In the meantime, have questions about this feature, please contact <a href=\"mailto:AMSLiveD@microsoft.com\">AMSLiveD@microsoft.com</a></p>\n"
}